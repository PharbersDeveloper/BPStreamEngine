/**
 * Autogenerated by Avro
 *
 * DO NOT EDIT DIRECTLY
 */
package com.pharbers.kafka.schema;

import org.apache.avro.specific.SpecificData;

@SuppressWarnings("all")
@org.apache.avro.specific.AvroGenerated
public class HiveTracebackTask extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  private static final long serialVersionUID = -4788531276674708533L;
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"HiveTracebackTask\",\"namespace\":\"com.pharbers.kafka.schema\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\"},{\"name\":\"traceId\",\"type\":\"string\"},{\"name\":\"datasetId\",\"type\":\"string\"},{\"name\":\"parentDatasetId\",\"type\":{\"type\":\"array\",\"items\":\"string\"}},{\"name\":\"parentUrl\",\"type\":{\"type\":\"record\",\"name\":\"ParentUrlRecord\",\"fields\":[{\"name\":\"MetaData\",\"type\":\"string\"},{\"name\":\"SampleData\",\"type\":\"string\"}]}},{\"name\":\"length\",\"type\":\"int\"},{\"name\":\"taskType\",\"type\":\"string\"},{\"name\":\"remarks\",\"type\":\"string\"}]}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
  @Deprecated public java.lang.CharSequence jobId;
  @Deprecated public java.lang.CharSequence traceId;
  @Deprecated public java.lang.CharSequence datasetId;
  @Deprecated public java.util.List<java.lang.CharSequence> parentDatasetId;
  @Deprecated public com.pharbers.kafka.schema.ParentUrlRecord parentUrl;
  @Deprecated public int length;
  @Deprecated public java.lang.CharSequence taskType;
  @Deprecated public java.lang.CharSequence remarks;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>.
   */
  public HiveTracebackTask() {}

  /**
   * All-args constructor.
   * @param jobId The new value for jobId
   * @param traceId The new value for traceId
   * @param datasetId The new value for datasetId
   * @param parentDatasetId The new value for parentDatasetId
   * @param parentUrl The new value for parentUrl
   * @param length The new value for length
   * @param taskType The new value for taskType
   * @param remarks The new value for remarks
   */
  public HiveTracebackTask(java.lang.CharSequence jobId, java.lang.CharSequence traceId, java.lang.CharSequence datasetId, java.util.List<java.lang.CharSequence> parentDatasetId, com.pharbers.kafka.schema.ParentUrlRecord parentUrl, java.lang.Integer length, java.lang.CharSequence taskType, java.lang.CharSequence remarks) {
    this.jobId = jobId;
    this.traceId = traceId;
    this.datasetId = datasetId;
    this.parentDatasetId = parentDatasetId;
    this.parentUrl = parentUrl;
    this.length = length;
    this.taskType = taskType;
    this.remarks = remarks;
  }

  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call.
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return jobId;
    case 1: return traceId;
    case 2: return datasetId;
    case 3: return parentDatasetId;
    case 4: return parentUrl;
    case 5: return length;
    case 6: return taskType;
    case 7: return remarks;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  // Used by DatumReader.  Applications should not call.
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: jobId = (java.lang.CharSequence)value$; break;
    case 1: traceId = (java.lang.CharSequence)value$; break;
    case 2: datasetId = (java.lang.CharSequence)value$; break;
    case 3: parentDatasetId = (java.util.List<java.lang.CharSequence>)value$; break;
    case 4: parentUrl = (com.pharbers.kafka.schema.ParentUrlRecord)value$; break;
    case 5: length = (java.lang.Integer)value$; break;
    case 6: taskType = (java.lang.CharSequence)value$; break;
    case 7: remarks = (java.lang.CharSequence)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  /**
   * Gets the value of the 'jobId' field.
   * @return The value of the 'jobId' field.
   */
  public java.lang.CharSequence getJobId() {
    return jobId;
  }

  /**
   * Sets the value of the 'jobId' field.
   * @param value the value to set.
   */
  public void setJobId(java.lang.CharSequence value) {
    this.jobId = value;
  }

  /**
   * Gets the value of the 'traceId' field.
   * @return The value of the 'traceId' field.
   */
  public java.lang.CharSequence getTraceId() {
    return traceId;
  }

  /**
   * Sets the value of the 'traceId' field.
   * @param value the value to set.
   */
  public void setTraceId(java.lang.CharSequence value) {
    this.traceId = value;
  }

  /**
   * Gets the value of the 'datasetId' field.
   * @return The value of the 'datasetId' field.
   */
  public java.lang.CharSequence getDatasetId() {
    return datasetId;
  }

  /**
   * Sets the value of the 'datasetId' field.
   * @param value the value to set.
   */
  public void setDatasetId(java.lang.CharSequence value) {
    this.datasetId = value;
  }

  /**
   * Gets the value of the 'parentDatasetId' field.
   * @return The value of the 'parentDatasetId' field.
   */
  public java.util.List<java.lang.CharSequence> getParentDatasetId() {
    return parentDatasetId;
  }

  /**
   * Sets the value of the 'parentDatasetId' field.
   * @param value the value to set.
   */
  public void setParentDatasetId(java.util.List<java.lang.CharSequence> value) {
    this.parentDatasetId = value;
  }

  /**
   * Gets the value of the 'parentUrl' field.
   * @return The value of the 'parentUrl' field.
   */
  public com.pharbers.kafka.schema.ParentUrlRecord getParentUrl() {
    return parentUrl;
  }

  /**
   * Sets the value of the 'parentUrl' field.
   * @param value the value to set.
   */
  public void setParentUrl(com.pharbers.kafka.schema.ParentUrlRecord value) {
    this.parentUrl = value;
  }

  /**
   * Gets the value of the 'length' field.
   * @return The value of the 'length' field.
   */
  public java.lang.Integer getLength() {
    return length;
  }

  /**
   * Sets the value of the 'length' field.
   * @param value the value to set.
   */
  public void setLength(java.lang.Integer value) {
    this.length = value;
  }

  /**
   * Gets the value of the 'taskType' field.
   * @return The value of the 'taskType' field.
   */
  public java.lang.CharSequence getTaskType() {
    return taskType;
  }

  /**
   * Sets the value of the 'taskType' field.
   * @param value the value to set.
   */
  public void setTaskType(java.lang.CharSequence value) {
    this.taskType = value;
  }

  /**
   * Gets the value of the 'remarks' field.
   * @return The value of the 'remarks' field.
   */
  public java.lang.CharSequence getRemarks() {
    return remarks;
  }

  /**
   * Sets the value of the 'remarks' field.
   * @param value the value to set.
   */
  public void setRemarks(java.lang.CharSequence value) {
    this.remarks = value;
  }

  /**
   * Creates a new HiveTracebackTask RecordBuilder.
   * @return A new HiveTracebackTask RecordBuilder
   */
  public static com.pharbers.kafka.schema.HiveTracebackTask.Builder newBuilder() {
    return new com.pharbers.kafka.schema.HiveTracebackTask.Builder();
  }

  /**
   * Creates a new HiveTracebackTask RecordBuilder by copying an existing Builder.
   * @param other The existing builder to copy.
   * @return A new HiveTracebackTask RecordBuilder
   */
  public static com.pharbers.kafka.schema.HiveTracebackTask.Builder newBuilder(com.pharbers.kafka.schema.HiveTracebackTask.Builder other) {
    return new com.pharbers.kafka.schema.HiveTracebackTask.Builder(other);
  }

  /**
   * Creates a new HiveTracebackTask RecordBuilder by copying an existing HiveTracebackTask instance.
   * @param other The existing instance to copy.
   * @return A new HiveTracebackTask RecordBuilder
   */
  public static com.pharbers.kafka.schema.HiveTracebackTask.Builder newBuilder(com.pharbers.kafka.schema.HiveTracebackTask other) {
    return new com.pharbers.kafka.schema.HiveTracebackTask.Builder(other);
  }

  /**
   * RecordBuilder for HiveTracebackTask instances.
   */
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<HiveTracebackTask>
    implements org.apache.avro.data.RecordBuilder<HiveTracebackTask> {

    private java.lang.CharSequence jobId;
    private java.lang.CharSequence traceId;
    private java.lang.CharSequence datasetId;
    private java.util.List<java.lang.CharSequence> parentDatasetId;
    private com.pharbers.kafka.schema.ParentUrlRecord parentUrl;
    private com.pharbers.kafka.schema.ParentUrlRecord.Builder parentUrlBuilder;
    private int length;
    private java.lang.CharSequence taskType;
    private java.lang.CharSequence remarks;

    /** Creates a new Builder */
    private Builder() {
      super(SCHEMA$);
    }

    /**
     * Creates a Builder by copying an existing Builder.
     * @param other The existing Builder to copy.
     */
    private Builder(com.pharbers.kafka.schema.HiveTracebackTask.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.jobId)) {
        this.jobId = data().deepCopy(fields()[0].schema(), other.jobId);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.traceId)) {
        this.traceId = data().deepCopy(fields()[1].schema(), other.traceId);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.datasetId)) {
        this.datasetId = data().deepCopy(fields()[2].schema(), other.datasetId);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.parentDatasetId)) {
        this.parentDatasetId = data().deepCopy(fields()[3].schema(), other.parentDatasetId);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.parentUrl)) {
        this.parentUrl = data().deepCopy(fields()[4].schema(), other.parentUrl);
        fieldSetFlags()[4] = true;
      }
      if (other.hasParentUrlBuilder()) {
        this.parentUrlBuilder = com.pharbers.kafka.schema.ParentUrlRecord.newBuilder(other.getParentUrlBuilder());
      }
      if (isValidValue(fields()[5], other.length)) {
        this.length = data().deepCopy(fields()[5].schema(), other.length);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.taskType)) {
        this.taskType = data().deepCopy(fields()[6].schema(), other.taskType);
        fieldSetFlags()[6] = true;
      }
      if (isValidValue(fields()[7], other.remarks)) {
        this.remarks = data().deepCopy(fields()[7].schema(), other.remarks);
        fieldSetFlags()[7] = true;
      }
    }

    /**
     * Creates a Builder by copying an existing HiveTracebackTask instance
     * @param other The existing instance to copy.
     */
    private Builder(com.pharbers.kafka.schema.HiveTracebackTask other) {
            super(SCHEMA$);
      if (isValidValue(fields()[0], other.jobId)) {
        this.jobId = data().deepCopy(fields()[0].schema(), other.jobId);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.traceId)) {
        this.traceId = data().deepCopy(fields()[1].schema(), other.traceId);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.datasetId)) {
        this.datasetId = data().deepCopy(fields()[2].schema(), other.datasetId);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.parentDatasetId)) {
        this.parentDatasetId = data().deepCopy(fields()[3].schema(), other.parentDatasetId);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.parentUrl)) {
        this.parentUrl = data().deepCopy(fields()[4].schema(), other.parentUrl);
        fieldSetFlags()[4] = true;
      }
      this.parentUrlBuilder = null;
      if (isValidValue(fields()[5], other.length)) {
        this.length = data().deepCopy(fields()[5].schema(), other.length);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.taskType)) {
        this.taskType = data().deepCopy(fields()[6].schema(), other.taskType);
        fieldSetFlags()[6] = true;
      }
      if (isValidValue(fields()[7], other.remarks)) {
        this.remarks = data().deepCopy(fields()[7].schema(), other.remarks);
        fieldSetFlags()[7] = true;
      }
    }

    /**
      * Gets the value of the 'jobId' field.
      * @return The value.
      */
    public java.lang.CharSequence getJobId() {
      return jobId;
    }

    /**
      * Sets the value of the 'jobId' field.
      * @param value The value of 'jobId'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setJobId(java.lang.CharSequence value) {
      validate(fields()[0], value);
      this.jobId = value;
      fieldSetFlags()[0] = true;
      return this;
    }

    /**
      * Checks whether the 'jobId' field has been set.
      * @return True if the 'jobId' field has been set, false otherwise.
      */
    public boolean hasJobId() {
      return fieldSetFlags()[0];
    }


    /**
      * Clears the value of the 'jobId' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder clearJobId() {
      jobId = null;
      fieldSetFlags()[0] = false;
      return this;
    }

    /**
      * Gets the value of the 'traceId' field.
      * @return The value.
      */
    public java.lang.CharSequence getTraceId() {
      return traceId;
    }

    /**
      * Sets the value of the 'traceId' field.
      * @param value The value of 'traceId'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setTraceId(java.lang.CharSequence value) {
      validate(fields()[1], value);
      this.traceId = value;
      fieldSetFlags()[1] = true;
      return this;
    }

    /**
      * Checks whether the 'traceId' field has been set.
      * @return True if the 'traceId' field has been set, false otherwise.
      */
    public boolean hasTraceId() {
      return fieldSetFlags()[1];
    }


    /**
      * Clears the value of the 'traceId' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder clearTraceId() {
      traceId = null;
      fieldSetFlags()[1] = false;
      return this;
    }

    /**
      * Gets the value of the 'datasetId' field.
      * @return The value.
      */
    public java.lang.CharSequence getDatasetId() {
      return datasetId;
    }

    /**
      * Sets the value of the 'datasetId' field.
      * @param value The value of 'datasetId'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setDatasetId(java.lang.CharSequence value) {
      validate(fields()[2], value);
      this.datasetId = value;
      fieldSetFlags()[2] = true;
      return this;
    }

    /**
      * Checks whether the 'datasetId' field has been set.
      * @return True if the 'datasetId' field has been set, false otherwise.
      */
    public boolean hasDatasetId() {
      return fieldSetFlags()[2];
    }


    /**
      * Clears the value of the 'datasetId' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder clearDatasetId() {
      datasetId = null;
      fieldSetFlags()[2] = false;
      return this;
    }

    /**
      * Gets the value of the 'parentDatasetId' field.
      * @return The value.
      */
    public java.util.List<java.lang.CharSequence> getParentDatasetId() {
      return parentDatasetId;
    }

    /**
      * Sets the value of the 'parentDatasetId' field.
      * @param value The value of 'parentDatasetId'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setParentDatasetId(java.util.List<java.lang.CharSequence> value) {
      validate(fields()[3], value);
      this.parentDatasetId = value;
      fieldSetFlags()[3] = true;
      return this;
    }

    /**
      * Checks whether the 'parentDatasetId' field has been set.
      * @return True if the 'parentDatasetId' field has been set, false otherwise.
      */
    public boolean hasParentDatasetId() {
      return fieldSetFlags()[3];
    }


    /**
      * Clears the value of the 'parentDatasetId' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder clearParentDatasetId() {
      parentDatasetId = null;
      fieldSetFlags()[3] = false;
      return this;
    }

    /**
      * Gets the value of the 'parentUrl' field.
      * @return The value.
      */
    public com.pharbers.kafka.schema.ParentUrlRecord getParentUrl() {
      return parentUrl;
    }

    /**
      * Sets the value of the 'parentUrl' field.
      * @param value The value of 'parentUrl'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setParentUrl(com.pharbers.kafka.schema.ParentUrlRecord value) {
      validate(fields()[4], value);
      this.parentUrlBuilder = null;
      this.parentUrl = value;
      fieldSetFlags()[4] = true;
      return this;
    }

    /**
      * Checks whether the 'parentUrl' field has been set.
      * @return True if the 'parentUrl' field has been set, false otherwise.
      */
    public boolean hasParentUrl() {
      return fieldSetFlags()[4];
    }

    /**
     * Gets the Builder instance for the 'parentUrl' field and creates one if it doesn't exist yet.
     * @return This builder.
     */
    public com.pharbers.kafka.schema.ParentUrlRecord.Builder getParentUrlBuilder() {
      if (parentUrlBuilder == null) {
        if (hasParentUrl()) {
          setParentUrlBuilder(com.pharbers.kafka.schema.ParentUrlRecord.newBuilder(parentUrl));
        } else {
          setParentUrlBuilder(com.pharbers.kafka.schema.ParentUrlRecord.newBuilder());
        }
      }
      return parentUrlBuilder;
    }

    /**
     * Sets the Builder instance for the 'parentUrl' field
     * @param value The builder instance that must be set.
     * @return This builder.
     */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setParentUrlBuilder(com.pharbers.kafka.schema.ParentUrlRecord.Builder value) {
      clearParentUrl();
      parentUrlBuilder = value;
      return this;
    }

    /**
     * Checks whether the 'parentUrl' field has an active Builder instance
     * @return True if the 'parentUrl' field has an active Builder instance
     */
    public boolean hasParentUrlBuilder() {
      return parentUrlBuilder != null;
    }

    /**
      * Clears the value of the 'parentUrl' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder clearParentUrl() {
      parentUrl = null;
      parentUrlBuilder = null;
      fieldSetFlags()[4] = false;
      return this;
    }

    /**
      * Gets the value of the 'length' field.
      * @return The value.
      */
    public java.lang.Integer getLength() {
      return length;
    }

    /**
      * Sets the value of the 'length' field.
      * @param value The value of 'length'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setLength(int value) {
      validate(fields()[5], value);
      this.length = value;
      fieldSetFlags()[5] = true;
      return this;
    }

    /**
      * Checks whether the 'length' field has been set.
      * @return True if the 'length' field has been set, false otherwise.
      */
    public boolean hasLength() {
      return fieldSetFlags()[5];
    }


    /**
      * Clears the value of the 'length' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder clearLength() {
      fieldSetFlags()[5] = false;
      return this;
    }

    /**
      * Gets the value of the 'taskType' field.
      * @return The value.
      */
    public java.lang.CharSequence getTaskType() {
      return taskType;
    }

    /**
      * Sets the value of the 'taskType' field.
      * @param value The value of 'taskType'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setTaskType(java.lang.CharSequence value) {
      validate(fields()[6], value);
      this.taskType = value;
      fieldSetFlags()[6] = true;
      return this;
    }

    /**
      * Checks whether the 'taskType' field has been set.
      * @return True if the 'taskType' field has been set, false otherwise.
      */
    public boolean hasTaskType() {
      return fieldSetFlags()[6];
    }


    /**
      * Clears the value of the 'taskType' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder clearTaskType() {
      taskType = null;
      fieldSetFlags()[6] = false;
      return this;
    }

    /**
      * Gets the value of the 'remarks' field.
      * @return The value.
      */
    public java.lang.CharSequence getRemarks() {
      return remarks;
    }

    /**
      * Sets the value of the 'remarks' field.
      * @param value The value of 'remarks'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder setRemarks(java.lang.CharSequence value) {
      validate(fields()[7], value);
      this.remarks = value;
      fieldSetFlags()[7] = true;
      return this;
    }

    /**
      * Checks whether the 'remarks' field has been set.
      * @return True if the 'remarks' field has been set, false otherwise.
      */
    public boolean hasRemarks() {
      return fieldSetFlags()[7];
    }


    /**
      * Clears the value of the 'remarks' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.HiveTracebackTask.Builder clearRemarks() {
      remarks = null;
      fieldSetFlags()[7] = false;
      return this;
    }

    @Override
    public HiveTracebackTask build() {
      try {
        HiveTracebackTask record = new HiveTracebackTask();
        record.jobId = fieldSetFlags()[0] ? this.jobId : (java.lang.CharSequence) defaultValue(fields()[0]);
        record.traceId = fieldSetFlags()[1] ? this.traceId : (java.lang.CharSequence) defaultValue(fields()[1]);
        record.datasetId = fieldSetFlags()[2] ? this.datasetId : (java.lang.CharSequence) defaultValue(fields()[2]);
        record.parentDatasetId = fieldSetFlags()[3] ? this.parentDatasetId : (java.util.List<java.lang.CharSequence>) defaultValue(fields()[3]);
        if (parentUrlBuilder != null) {
          record.parentUrl = this.parentUrlBuilder.build();
        } else {
          record.parentUrl = fieldSetFlags()[4] ? this.parentUrl : (com.pharbers.kafka.schema.ParentUrlRecord) defaultValue(fields()[4]);
        }
        record.length = fieldSetFlags()[5] ? this.length : (java.lang.Integer) defaultValue(fields()[5]);
        record.taskType = fieldSetFlags()[6] ? this.taskType : (java.lang.CharSequence) defaultValue(fields()[6]);
        record.remarks = fieldSetFlags()[7] ? this.remarks : (java.lang.CharSequence) defaultValue(fields()[7]);
        return record;
      } catch (Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }

  private static final org.apache.avro.io.DatumWriter
    WRITER$ = new org.apache.avro.specific.SpecificDatumWriter(SCHEMA$);


  private static final org.apache.avro.io.DatumReader
    READER$ = new org.apache.avro.specific.SpecificDatumReader(SCHEMA$);


}
